<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Home | Natasha Smith Portfolio</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content><meta name=generator content="Hugo 0.142.0"><link rel=stylesheet href=/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css><link rel=stylesheet href=/css/custom.css></head><body class="ma0 avenir bg-near-white"><nav class="pa3 pa4-ns flex justify-end items-center"><ul class="list flex ma0 pa0"><li class=ml3><a class="link dim dark-gray f5" href=/>Home</a></li><li class=ml3><a class="link dim dark-gray f5" href=/about/>About</a></li><li class=ml3><a class="link dim dark-gray f5" href=/projects/>Projects</a></li><li class=ml3><a class="link dim dark-gray f5" href=/contact/>Contact</a></li></ul></nav><main class=pb7 role=main><article class="cf pa3 pa4-m pa4-l"><div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray"><p>Below you will find pages that utilize the taxonomy term “Home”</p></div></article><div class="mw8 center"><section class="flex-ns flex-wrap justify-around mt5"><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project10_images/pr10.jpg alt="PART 4. Addressing Class Imbalance in Medical Image Datasets. Tackling Class Imbalance in Histopathology: Strategies and Insights" class="w-100 br2 mb3">
<span class="f6 db">Cancer Detection in Histopathology: The Role of Colour Normalisation in Model Calibration and Performance</span><h1 class="f3 near-black"><a href=/projects/project10/project10_4/ class="link black dim">PART 4. Addressing Class Imbalance in Medical Image Datasets. Tackling Class Imbalance in Histopathology: Strategies and Insights</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project10_images/pr10.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/ColourNorm-Histopathology-DeepLearning target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>In medical imaging datasets like histopathology, class imbalance is a common and critical challenge. For instance, datasets may contain significantly more benign samples than malignant ones, making it harder for models to learn to detect the minority class accurately. This can lead to poor sensitivity (recall), which is especially problematic in healthcare where identifying true positives is critical.</p><p>In this blog, we explore:</p></div><a href=/projects/project10/project10_4/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project10_images/pr10.jpg alt="PART 5. Evaluation and Calibration: Building Trust in Medical AI Models" class="w-100 br2 mb3">
<span class="f6 db">Cancer Detection in Histopathology: The Role of Colour Normalisation in Model Calibration and Performance</span><h1 class="f3 near-black"><a href=/projects/project10/project10_5/ class="link black dim">PART 5. Evaluation and Calibration: Building Trust in Medical AI Models</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project10_images/pr10.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/ColourNorm-Histopathology-DeepLearning target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Deep learning models are increasingly used in critical domains like healthcare. However, high accuracy alone doesn’t guarantee a model’s reliability.</p><p>For medical AI systems, evaluation and calibration are key to building trust, ensuring fair predictions, and avoiding costly mistakes.</p><p>In this blog, we’ll explore:</p><ul><li>The importance of model calibration.</li><li>Key metrics: <strong>F1-score</strong>, <strong>Brier score loss</strong>, <strong>ROC-AUC</strong>, and <strong>confusion matrices</strong>.</li><li>How to visualise and measure calibration using calibration curves.</li></ul><h3 id=why-model-calibration-and-evaluation-matter>Why Model Calibration and Evaluation Matter</h3><p>Medical imaging models often predict probabilities (e.g., &ldquo;90% chance of malignancy&rdquo;). But probability alone isn’t useful unless it reflects reality. For instance:</p></div><a href=/projects/project10/project10_5/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div></section></div></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=http://localhost:1313/>&copy; Natasha Smith Portfolio 2025</a><div><div class=ananke-socials></div></div></div></footer></body></html>