<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Image Classification | Natasha Smith Portfolio</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content><meta name=generator content="Hugo 0.142.0"><link rel=stylesheet href=/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css><link rel=stylesheet href=/css/custom.css></head><body class="ma0 avenir bg-near-white"><nav class="pa3 pa4-ns flex justify-end items-center"><ul class="list flex ma0 pa0"><li class=ml3><a class="link dim dark-gray f5" href=/>Home</a></li><li class=ml3><a class="link dim dark-gray f5" href=/about/>About</a></li><li class=ml3><a class="link dim dark-gray f5" href=/projects/>Projects</a></li><li class=ml3><a class="link dim dark-gray f5" href=/contact/>Contact</a></li></ul></nav><main class=pb7 role=main><article class="cf pa3 pa4-m pa4-l"><div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray"><p>Below you will find pages that utilize the taxonomy term “Image Classification”</p></div></article><div class="mw8 center"><section class="flex-ns flex-wrap justify-around mt5"><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 1. Decoding Fashion MNIST: A Modern Benchmark for Deep Learning." class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_1/ class="link black dim">Part 1. Decoding Fashion MNIST: A Modern Benchmark for Deep Learning.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>You’ve seen it before: the iconic handwritten digits from the MNIST dataset, the quintessential benchmark for machine learning enthusiasts.</p><p>But here’s the thing—MNIST is old news. It’s solved, overused, and no longer representative of real-world challenges. Fashion MNIST is a modern, robust alternative that brings fresh complexity to the table.</p><p>Fashion MNIST is a game-changer. With its focus on apparel images like shirts, sneakers, and dresses, it mirrors the kind of messy, nuanced data we deal with today.</p></div><a href=/projects/project12/project12_1/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project5_images/pr5.jpg alt="Part 1. Challenges in Medical Imaging Datasets." class="w-100 br2 mb3">
<span class="f6 db">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</span><h1 class="f3 near-black"><a href=/projects/project5/project5_1/ class="link black dim">Part 1. Challenges in Medical Imaging Datasets.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project5_images/pr5.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/pneumonia-detection-CNN target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Medical imaging datasets provide critical opportunities for deep learning (DL) applications, but they also come with unique challenges.</p><p>In this project, aimed at detecting pneumonia using chest X-rays, we faced hurdles like <strong>dataset imbalance</strong> and <strong>small validation sets</strong>, which can hinder model performance.</p><p>This blog discusses the key challenges and demonstrates pre-processing techniques—such as dataset re-sampling, data augmentation, and re-splitting—that helped us overcome these obstacles.</p></div><a href=/projects/project5/project5_1/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project5_images/pr5.jpg alt="Part 2. Boosting Model Generalisation with Data Augmentation." class="w-100 br2 mb3">
<span class="f6 db">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</span><h1 class="f3 near-black"><a href=/projects/project5/project5_2/ class="link black dim">Part 2. Boosting Model Generalisation with Data Augmentation.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project5_images/pr5.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/pneumonia-detection-CNN target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Deep learning (DL) models often struggle with over-fitting, especially when trained on limited datasets.</p><p>To overcome this challenge in our pneumonia detection project, we used <strong>data augmentation</strong> (DA) techniques to artificially expand the training dataset.</p><p>DA techniques, such as rotations, scaling, flipping, and zooming, helped improve the model&rsquo;s generalisation to unseen chest X-ray images.</p><p>This blog explains the DA techniques applied, demonstrates the Python code used, and highlights how augmentation enhanced the performance of both the manual CNN and the pre-trained VGG16 models.</p></div><a href=/projects/project5/project5_2/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 2. Designing Dense Neural Networks: Lessons from Fashion MNIST." class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_2/ class="link black dim">Part 2. Designing Dense Neural Networks: Lessons from Fashion MNIST.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Designing neural networks (NNs) is an art as much as it is a science. When faced with the challenge of classifying Fashion MNIST images, I needed a lightweight yet powerful architecture to handle the complexity of apparel images. Dense neural networks, with their fully connected layers, were the perfect choice for this task.</p><p>In this blog, we’ll walk through:</p><ul><li>How dense neural networks work and their role in image classification.</li><li>Designing an efficient architecture using activation functions and layers.</li><li>Practical lessons learned while optimising performance with Fashion MNIST.</li></ul><p>By the end, you’ll have a clear roadmap to build your own dense networks for image classification tasks.
Let’s dive in!</p></div><a href=/projects/project12/project12_2/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project5_images/pr5.jpg alt="Part 3. Manual CNN vs. Pre-Trained VGG16: A Comparative Analysis." class="w-100 br2 mb3">
<span class="f6 db">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</span><h1 class="f3 near-black"><a href=/projects/project5/project5_3/ class="link black dim">Part 3. Manual CNN vs. Pre-Trained VGG16: A Comparative Analysis.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project5_images/pr5.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/pneumonia-detection-CNN target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Deep learning (DL) provides multiple pathways to solving problems, including designing custom architectures or leveraging pre-trained models.</p><p>In this blog, we compare the performance of a <strong>manual CNN</strong> and the <strong>VGG16 pre-trained model</strong> for pneumonia detection.</p><p>While the manual CNN was lightweight and tailored to the dataset, VGG16 brought the power of transfer learning with its pre-trained <strong>ImageNet</strong> weights.</p><p>This comparative analysis explores their architectures, training strategies, and results.</p></div><a href=/projects/project5/project5_3/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 3. ReLU vs Sigmoid: Which Activation Function Wins on Fashion MNIST?" class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_3/ class="link black dim">Part 3. ReLU vs Sigmoid: Which Activation Function Wins on Fashion MNIST?</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>When building neural networks (NNs), the activation function you choose can make or break your model. It’s the part of the network that decides whether a neuron &ldquo;fires&rdquo; and passes information forward.</p><p>For years, Sigmoid was the go-to activation function, but then ReLU came along, revolutionising deep learning with its simplicity and effectiveness. But how do these activation functions stack up against each other in practice?</p></div><a href=/projects/project12/project12_3/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project5_images/pr5.jpg alt="Part 4. Evaluating CNN Models for Pneumonia Detection." class="w-100 br2 mb3">
<span class="f6 db">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</span><h1 class="f3 near-black"><a href=/projects/project5/project5_4/ class="link black dim">Part 4. Evaluating CNN Models for Pneumonia Detection.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project5_images/pr5.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/pneumonia-detection-CNN target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Evaluating the performance of deep learning models in medical imaging projects requires more than just accuracy.</p><p>Metrics like <strong>precision</strong>, <strong>recall</strong>, and <strong>F1-score</strong> provide deeper insights, especially when minimising false negatives is critical, as in pneumonia detection.</p><p>This blog explores how our models—<strong>Manual CNN</strong> and <strong>VGG16</strong>—were evaluated and highlights the role of confusion matrices in understanding their performance.</p><h3 id=metrics-for-evaluation>Metrics for Evaluation</h3><ol><li><p><strong>Accuracy</strong>: The percentage of correctly classified samples.</p></div><a href=/projects/project5/project5_4/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 4. Hyperparameter Tuning for Neural Networks: The Fashion MNIST Approach." class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_4/ class="link black dim">Part 4. Hyperparameter Tuning for Neural Networks: The Fashion MNIST Approach.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>When training neural networks (NNs), every parameter matters. Hyperparameters like learning rate and batch size aren’t learned by the model—they’re chosen by you. These settings can make or break your model’s performance. But how do you find the right combination?</p><p>In this blog, I’ll take you through my experience fine-tuning hyperparameters for a NN trained on the Fashion MNIST dataset. We’ll cover:</p></div><a href=/projects/project12/project12_4/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project5_images/pr5.jpg alt="Part 5. Insights from Sensitivity and Specificity Analysis in Pneumonia Detection." class="w-100 br2 mb3">
<span class="f6 db">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</span><h1 class="f3 near-black"><a href=/projects/project5/project5_5/ class="link black dim">Part 5. Insights from Sensitivity and Specificity Analysis in Pneumonia Detection.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project5_images/pr5.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/pneumonia-detection-CNN target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>When evaluating AI models for medical diagnostics, metrics like <strong>sensitivity</strong> and <strong>specificity</strong> are crucial.</p><p>Unlike general-purpose accuracy, these metrics provide deeper insights into how well a model distinguishes between true positive and true negative cases.</p><p>For pneumonia detection, where false negatives can have severe consequences, understanding these metrics is essential.</p><p>In this blog, I break down sensitivity and specificity, demonstrate their importance in model evaluation, and analyse how they influenced our choice between the Manual CNN and VGG16 models.</p></div><a href=/projects/project5/project5_5/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 5. Perfecting Data Splits: Train-Test and Validation Strategies for Reliable Results. How thoughtful data splitting practices ensure consistent performance in machine learning pipelines." class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_5/ class="link black dim">Part 5. Perfecting Data Splits: Train-Test and Validation Strategies for Reliable Results. How thoughtful data splitting practices ensure consistent performance in machine learning pipelines.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Machine learning models are only as good as the data they’re trained on. But even the best dataset won’t save you if your data splits are flawed. Splitting data into training, validation, and test sets seems straightforward, but small mistakes can lead to big problems like overfitting, underfitting, or unreliable performance metrics.</p><p>You have a perfectly balanced dataset. Every class is equally represented, and it seems like splitting the data into training, testing, and validation sets should be a no-brainer. But even with balanced datasets like Fashion MNIST, thoughtful splitting is critical to ensure fair evaluation, reproducibility, and proper generalisation.</p></div><a href=/projects/project12/project12_5/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project5_images/pr5.jpg alt="Part 6. Future Directions for AI-Assisted Medical Imaging." class="w-100 br2 mb3">
<span class="f6 db">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</span><h1 class="f3 near-black"><a href=/projects/project5/project5_6/ class="link black dim">Part 6. Future Directions for AI-Assisted Medical Imaging.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p><figure><img src=/images/project5_images/pr5.jpg></figure><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/pneumonia-detection-CNN target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>AI made significant strides in medical imaging, as demonstrated by our pneumonia detection project.</p><p>However, the journey is far from complete. Future advancements in deep learning, real-world deployment, and ethical considerations will shape the role of AI in diagnostics and healthcare delivery.</p><p>In this blog, we explore the potential and challenges of AI in medical imaging, including future directions for improving model performance, ensuring ethical deployment, and scaling solutions for global healthcare.</p></div><a href=/projects/project5/project5_6/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 6. Simplicity and Control in Optimising Neural Networks: The Stochastic Gradient Descent optimiser and its role in fine-tuning neural networks." class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_6/ class="link black dim">Part 6. Simplicity and Control in Optimising Neural Networks: The Stochastic Gradient Descent optimiser and its role in fine-tuning neural networks.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Training a neural network requires more than just a good dataset or an effective architecture—it requires the right optimiser. Stochastic Gradient Descent (SGD) is a staple of deep learning.</p><p>In my Fashion MNIST project, I used Stochastic Gradient Descent (SGD) to optimise a dense neural network. Why? Because simplicity doesn’t just work—it excels, especially when resources are limited or interpretability is key.</p></div><a href=/projects/project12/project12_6/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 7. The Power of Sparse Categorical Crossentropy: A guide to understanding loss functions for multi-class classification." class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_7/ class="link black dim">Part 7. The Power of Sparse Categorical Crossentropy: A guide to understanding loss functions for multi-class classification.</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Choosing the right loss function is one of the most critical decisions when building a neural network. For multi-class classification tasks, like predicting clothing categories in Fashion MNIST, the sparse categorical crossentropy (SCC) loss function is often the go-to solution. But what makes it so effective?</p><p>This blog dives into:</p><ul><li>What sparse categorical crossentropy is and how it works.</li><li>Why it’s the ideal choice for tasks involving multiple classes.</li><li>How to implement it efficiently in TensorFlow/Keras.</li></ul><p>By the end, you’ll have a solid understanding of this loss function and when to use it in your own projects.</p></div><a href=/projects/project12/project12_7/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Part 8. Trial and Error in Neural Network Training: Lessons from Fashion MNIST" class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/project12_8/ class="link black dim">Part 8. Trial and Error in Neural Network Training: Lessons from Fashion MNIST</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><figure><img src=/images/project12_images/pr12.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/Designing-Dense-NNs-Using-MNIST target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Training neural networks (NNs) is a lot like navigating uncharted waters. No matter how much preparation or theoretical knowledge you have, it’s the experiments—and the inevitable mistakes—that shape your skills.</p><p>As a data scientist working on Fashion MNIST, a dataset of 28x28 grayscale images representing 10 clothing categories, I realised that building effective models requires more than just writing code; it demands iteration, debugging, and adaptability.</p></div><a href=/projects/project12/project12_8/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project5_images/pr5.jpg alt="AI-Driven Pneumonia Detection Using Convolutional Neural Networks" class="w-100 br2 mb3">
<span class="f6 db">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</span><h1 class="f3 near-black"><a href=/projects/project5/ class="link black dim">AI-Driven Pneumonia Detection Using Convolutional Neural Networks</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p>This section showcases the technical blogs related to this project. Click on each post to learn more about the project components.</p></div><a href=/projects/project5/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><img src=/images/project12_images/pr12.jpg alt="Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment" class="w-100 br2 mb3">
<span class="f6 db">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</span><h1 class="f3 near-black"><a href=/projects/project12/ class="link black dim">Building Robust CNN Pipelines for Fashion MNIST: From Data to Deployment</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p>This section showcases the technical blogs related to this project. Each blog focuses on a specific aspect. Click on each post to learn more about the project components.</p></div><a href=/projects/project12/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></div></section></div></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=http://localhost:1313/>&copy; Natasha Smith Portfolio 2025</a><div><div class=ananke-socials></div></div></div></footer></body></html>