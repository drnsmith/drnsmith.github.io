<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Feature Engineering on Natasha Smith Portfolio</title><link>http://localhost:1313/tags/feature-engineering/</link><description>Recent content in Feature Engineering on Natasha Smith Portfolio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 20 Nov 2023 10:58:08 -0400</lastBuildDate><atom:link href="http://localhost:1313/tags/feature-engineering/index.xml" rel="self" type="application/rss+xml"/><item><title>Part 1. Cleaning the Air: Data Pre-processing for PM10 Prediction.</title><link>http://localhost:1313/projects/project8/project8_1/</link><pubDate>Mon, 20 Nov 2023 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project8/project8_1/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project8_images/pr8.jpg"
 alt="Photo by Dom J on Pexels">&lt;figcaption>
 &lt;p>Photo by Dom J on Pexels&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/PM-London-Pollution" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>Have you ever stopped to think about the data behind environmental predictions?&lt;/p>
&lt;p>We hear a lot about air pollution and its devastating effects on our health, but what’s often overlooked is the behind-the-scenes work required to make accurate predictions.&lt;/p>
&lt;p>The first step in any data-driven environmental project is cleaning the data—and let me tell you, it’s not as simple as it sounds.&lt;/p></description></item><item><title>Part 1. Building an AI-Powered Recipe Difficulty Classifier: A Journey Through NLP and ML.</title><link>http://localhost:1313/projects/project1/project1_1/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_1/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;div style="display: flex; align-items: center; gap: 10px;">
 &lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank" style="text-decoration: none;">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width: 40px; height: 40px; vertical-align: middle;">
 &lt;/a>
 &lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank" style="font-weight: bold; color: black;">
 View Project on GitHub
 &lt;/a>
&lt;/div>
&lt;h2 id="introduction">&lt;strong>Introduction&lt;/strong>&lt;/h2>
&lt;p>Cooking varies in complexity. Some recipes are straightforward, while others demand precision, technique, and skill. The challenge was to develop a ML model that classifies recipes into four difficulty levels—&lt;strong>Easy, Medium, Hard, and Very Hard&lt;/strong>—using &lt;strong>Natural Language Processing (NLP)&lt;/strong> and &lt;strong>Machine Learning (ML)&lt;/strong>. In this post, I focus on &lt;strong>data collection, cleaning, and pre-processing&lt;/strong>, which lay the foundation for training a robust ML model.&lt;/p></description></item><item><title>Part 2. Exploring the Data: Understanding PM10 and Its Impact Through EDA.</title><link>http://localhost:1313/projects/project8/project8_2/</link><pubDate>Mon, 20 Nov 2023 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project8/project8_2/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project8_images/pr8.jpg"
 alt="Photo by Dom J on Pexels">&lt;figcaption>
 &lt;p>Photo by Dom J on Pexels&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/PM-London-Pollution" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>Behind every successful machine learning (ML) project is a stage that is equal parts science and art: &lt;strong>Exploratory Data Analysis (EDA)&lt;/strong>.&lt;/p>
&lt;p>This step is where we uncover the hidden stories in the data, identify patterns, and gain insights that inform the model-building process.&lt;/p>
&lt;p>When working with air pollution data, EDA plays a vital role in answering key questions:&lt;/p></description></item><item><title>Part 2. Exploring Feature Engineering for Recipe Classification: How AI Understands Cooking Complexity.</title><link>http://localhost:1313/projects/project1/project1_2/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_2/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>In ML, features are measurable characteristics or properties that help a model make predictions. In recipe classification, features such as ingredient complexity, cooking techniques, and step count become powerful predictors of recipe difficulty. Feature engineering helps us take unstructured data, such as recipe instructions, and turn it into structured data that the model can understand.&lt;/p>
&lt;p>For example, a recipe with advanced ingredients (like &amp;ldquo;saffron&amp;rdquo; or &amp;ldquo;truffle oil&amp;rdquo;) is likely to be more challenging than one with everyday items like &amp;ldquo;salt&amp;rdquo; or &amp;ldquo;flour.&amp;rdquo; Similarly, recipes that involve techniques like &amp;ldquo;blanching&amp;rdquo; or &amp;ldquo;flambé&amp;rdquo; tend to require more skill than those involving basic steps like &amp;ldquo;stirring.&amp;rdquo;&lt;/p></description></item><item><title>Part 3. Regression Models for Air Quality Prediction: From Simplicity to Accuracy.</title><link>http://localhost:1313/projects/project8/project8_3/</link><pubDate>Mon, 20 Nov 2023 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project8/project8_3/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project8_images/pr8.jpg"
 alt="Photo by Dom J on Pexels">&lt;figcaption>
 &lt;p>Photo by Dom J on Pexels&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/PM-London-Pollution" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>Predicting air pollution isn’t just about crunching numbers—it’s about finding patterns, building models, and learning how different variables interact with one another.&lt;/p>
&lt;p>In this blog, I take the first step toward accurate PM10 predictions by exploring regression models. These models form the backbone of many machine learning (ML) projects, providing interpretable results and insights into the relationships between variables.&lt;/p></description></item><item><title>PART 3. Choosing the Right Model: Training and Evaluating an AI Recipe Difficulty Classifier</title><link>http://localhost:1313/projects/project1/project1_3/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_3/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>In the previous post, I explored how feature engineering transforms raw recipe data into valuable insights for predicting recipe difficulty. With features like ingredient complexity, technique identification, and step count, my dataset is now ready for the next stage: selecting, training, and evaluating a machine learning model that can classify recipes by difficulty level. Model selection is a crucial step in building a successful classifier. In this post, I’ll walk you through the models I tested, the training process, and the metrics I used to evaluate performance.&lt;/p></description></item><item><title>Part 4. Advanced Machine Learning for PM10 Prediction: Random Forest, XGBoost, and More.</title><link>http://localhost:1313/projects/project8/project8_4/</link><pubDate>Mon, 20 Nov 2023 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project8/project8_4/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project8_images/pr8.jpg"
 alt="Photo by Dom J on Pexels">&lt;figcaption>
 &lt;p>Photo by Dom J on Pexels&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/PM-London-Pollution" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>Regression models laid a solid foundation for PM10 prediction, but air pollution is a complex phenomenon influenced by nonlinear and time-dependent factors.&lt;/p>
&lt;p>To capture these intricacies, advanced machine learning models like neural networks (NNs) and ensemble methods come into play. These models are capable of uncovering patterns and relationships that simpler models might overlook.&lt;/p></description></item><item><title>Part 4. Tackling Overfitting in Recipe Difficulty Classification: Lessons Learned and Solutions.</title><link>http://localhost:1313/projects/project1/project1_4/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_4/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>As I progressed with training my AI-powered recipe classifier, I noticed a common issue creeping in: &lt;em>overfitting&lt;/em>, which happens when a model performs well on the training data but struggles to generalise to new, unseen data. In ML, this can result in poor accuracy on validation or test data. In this blog, I’ll walk you through how I identified overfitting in my model and the steps I took to address it. I’ll also explain the visual clues from training and validation loss/accuracy graphs that helped me recognise this issue.&lt;/p></description></item><item><title>Part 5. Evaluating and Selecting the Best Models for PM10 Prediction.</title><link>http://localhost:1313/projects/project8/project8_5/</link><pubDate>Mon, 20 Nov 2023 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project8/project8_5/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project8_images/pr8.jpg"
 alt="Photo by Dom J on Pexels">&lt;figcaption>
 &lt;p>Photo by Dom J on Pexels&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/PM-London-Pollution" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>After building and testing various machine learning models, the next critical step is evaluating their performance and selecting the best ones for deployment.&lt;/p>
&lt;p>In this blog, we’ll compare models using rigorous metrics like RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error).&lt;/p>
&lt;p>We’ll also explore hyperparameter tuning for neural networks, leveraging GridSearchCV for optimal performance.&lt;/p></description></item><item><title>Part 5. Interpreting the AI Recipe Classifier with LIME: Making ML Transparent.</title><link>http://localhost:1313/projects/project1/project1_5/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_5/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>In building a recipe difficulty classifier, I wanted to make sure the model&amp;rsquo;s predictions weren’t just accurate but also understandable. For anyone working with ML, especially in fields where transparency is key, model interpretability is crucial. This is where LIME (Local Interpretable Model-Agnostic Explanations) comes in.
In this blog post, I’ll walk you through how I used LIME to make sense of my classifier’s decisions, ensuring that its predictions are grounded and explainable.&lt;/p></description></item><item><title>Part 6. From Data to Action: What Pollution Data and AI Teach Us About Cleaner Air.</title><link>http://localhost:1313/projects/project8/project8_6/</link><pubDate>Mon, 20 Nov 2023 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project8/project8_6/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project8_images/pr8.jpg"
 alt="Photo by Dom J on Pexels">&lt;figcaption>
 &lt;p>Photo by Dom J on Pexels&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/PM-London-Pollution" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>Predicting PM10 and other pollutants is not just about building models or visualising data—it&amp;rsquo;s about understanding the invisible threats in the air we breathe and finding ways to address them.&lt;/p>
&lt;p>After exploring data pre-processing, modelling, and evaluation, this final piece reflects on the insights gained and their real-world implications.&lt;/p>
&lt;p>I’ll discuss how the results from this project—built on advanced AI/ML techniques—can guide better decision-making for policymakers, businesses, and citizens alike.&lt;/p></description></item><item><title>Part 6. Deploying an AI Model for Recipe Classification: Bringing the Classifier to Life.</title><link>http://localhost:1313/projects/project1/project1_6/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_6/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>Once a model that classifies recipes by difficulty level is built and trained , the next challenge is deploying it into a real-world environment. In this blog, we’ll cover the process of moving our trained model from a development setting to a production environment. Deployment enables the model to make predictions and serve users in real-time, opening up possibilities for applications like recipe recommendation engines, cooking assistant apps, or culinary content platforms.&lt;/p></description></item><item><title>Predicting Pollution (PM10 Levels): Leveraging Data Science and Machine Learning to Combat Urban Air Pollution in London, UK</title><link>http://localhost:1313/projects/project8/</link><pubDate>Mon, 20 Nov 2023 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project8/</guid><description>&lt;p>This section showcases the technical blogs related to this project. Click on each post to learn more about the project components.&lt;/p></description></item><item><title>AI-Powered Recipe Difficulty Classification</title><link>http://localhost:1313/projects/project1/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/</guid><description>&lt;p>This section showcases the technical blogs related to this project. Click on each post to learn more about the project components.&lt;/p></description></item></channel></rss>