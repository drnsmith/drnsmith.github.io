<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Text Processing on Natasha Smith Portfolio</title><link>http://localhost:1313/tags/text-processing/</link><description>Recent content in Text Processing on Natasha Smith Portfolio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 09 Apr 2022 10:58:08 -0400</lastBuildDate><atom:link href="http://localhost:1313/tags/text-processing/index.xml" rel="self" type="application/rss+xml"/><item><title>Part 1. Building an AI-Powered Recipe Difficulty Classifier: A Journey Through NLP and ML.</title><link>http://localhost:1313/projects/project1/project1_1/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_1/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;div style="display: flex; align-items: center; gap: 10px;">
 &lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank" style="text-decoration: none;">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width: 40px; height: 40px; vertical-align: middle;">
 &lt;/a>
 &lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank" style="font-weight: bold; color: black;">
 View Project on GitHub
 &lt;/a>
&lt;/div>
&lt;h2 id="introduction">&lt;strong>Introduction&lt;/strong>&lt;/h2>
&lt;p>Cooking varies in complexity. Some recipes are straightforward, while others demand precision, technique, and skill. The challenge was to develop a ML model that classifies recipes into four difficulty levels—&lt;strong>Easy, Medium, Hard, and Very Hard&lt;/strong>—using &lt;strong>Natural Language Processing (NLP)&lt;/strong> and &lt;strong>Machine Learning (ML)&lt;/strong>. In this post, I focus on &lt;strong>data collection, cleaning, and pre-processing&lt;/strong>, which lay the foundation for training a robust ML model.&lt;/p></description></item><item><title>Part 2. Exploring Feature Engineering for Recipe Classification: How AI Understands Cooking Complexity.</title><link>http://localhost:1313/projects/project1/project1_2/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_2/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>In ML, features are measurable characteristics or properties that help a model make predictions. In recipe classification, features such as ingredient complexity, cooking techniques, and step count become powerful predictors of recipe difficulty. Feature engineering helps us take unstructured data, such as recipe instructions, and turn it into structured data that the model can understand.&lt;/p>
&lt;p>For example, a recipe with advanced ingredients (like &amp;ldquo;saffron&amp;rdquo; or &amp;ldquo;truffle oil&amp;rdquo;) is likely to be more challenging than one with everyday items like &amp;ldquo;salt&amp;rdquo; or &amp;ldquo;flour.&amp;rdquo; Similarly, recipes that involve techniques like &amp;ldquo;blanching&amp;rdquo; or &amp;ldquo;flambé&amp;rdquo; tend to require more skill than those involving basic steps like &amp;ldquo;stirring.&amp;rdquo;&lt;/p></description></item><item><title>PART 3. Choosing the Right Model: Training and Evaluating an AI Recipe Difficulty Classifier</title><link>http://localhost:1313/projects/project1/project1_3/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_3/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>In the previous post, I explored how feature engineering transforms raw recipe data into valuable insights for predicting recipe difficulty. With features like ingredient complexity, technique identification, and step count, my dataset is now ready for the next stage: selecting, training, and evaluating a machine learning model that can classify recipes by difficulty level. Model selection is a crucial step in building a successful classifier. In this post, I’ll walk you through the models I tested, the training process, and the metrics I used to evaluate performance.&lt;/p></description></item><item><title>Part 4. Tackling Overfitting in Recipe Difficulty Classification: Lessons Learned and Solutions.</title><link>http://localhost:1313/projects/project1/project1_4/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_4/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>As I progressed with training my AI-powered recipe classifier, I noticed a common issue creeping in: &lt;em>overfitting&lt;/em>, which happens when a model performs well on the training data but struggles to generalise to new, unseen data. In ML, this can result in poor accuracy on validation or test data. In this blog, I’ll walk you through how I identified overfitting in my model and the steps I took to address it. I’ll also explain the visual clues from training and validation loss/accuracy graphs that helped me recognise this issue.&lt;/p></description></item><item><title>Part 5. Interpreting the AI Recipe Classifier with LIME: Making ML Transparent.</title><link>http://localhost:1313/projects/project1/project1_5/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_5/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>In building a recipe difficulty classifier, I wanted to make sure the model&amp;rsquo;s predictions weren’t just accurate but also understandable. For anyone working with ML, especially in fields where transparency is key, model interpretability is crucial. This is where LIME (Local Interpretable Model-Agnostic Explanations) comes in.
In this blog post, I’ll walk you through how I used LIME to make sense of my classifier’s decisions, ensuring that its predictions are grounded and explainable.&lt;/p></description></item><item><title>Part 6. Deploying an AI Model for Recipe Classification: Bringing the Classifier to Life.</title><link>http://localhost:1313/projects/project1/project1_6/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/project1_6/</guid><description>&lt;figure>&lt;img src="http://localhost:1313/images/project1_images/pr1.jpg">
&lt;/figure>

&lt;p>&lt;strong>View Project on GitHub&lt;/strong>:&lt;/p>
&lt;a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank">
 &lt;img src="http://localhost:1313/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
 &lt;/a>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>Once a model that classifies recipes by difficulty level is built and trained , the next challenge is deploying it into a real-world environment. In this blog, we’ll cover the process of moving our trained model from a development setting to a production environment. Deployment enables the model to make predictions and serve users in real-time, opening up possibilities for applications like recipe recommendation engines, cooking assistant apps, or culinary content platforms.&lt;/p></description></item><item><title>AI-Powered Recipe Difficulty Classification</title><link>http://localhost:1313/projects/project1/</link><pubDate>Sat, 09 Apr 2022 10:58:08 -0400</pubDate><guid>http://localhost:1313/projects/project1/</guid><description>&lt;p>This section showcases the technical blogs related to this project. Click on each post to learn more about the project components.&lt;/p></description></item></channel></rss>