<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>PART 1. Colour Normalisation in Histopathology. Enhancing Medical Image Consistency: Colour Normalisation Techniques for Histopathology | Natasha Smith Portfolio</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Explore how colour normalisation techniques can reduce staining variability in histopathology slides, improving the performance of machine learning models."><meta name=generator content="Hugo 0.142.0"><link rel=stylesheet href=/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css><link rel=stylesheet href=/css/custom.css></head><body class="ma0 avenir bg-near-white"><nav class="pa3 pa4-ns flex justify-end items-center"><ul class="list flex ma0 pa0"><li class=ml3><a class="link dim dark-gray f5" href=/>Home</a></li><li class=ml3><a class="link dim dark-gray f5" href=/about/>About</a></li><li class=ml3><a class="link dim dark-gray f5" href=/projects/>Projects</a></li><li class=ml3><a class="link dim dark-gray f5" href=/contact/>Contact</a></li></ul></nav><header class=page-header style=background-image:url(/images/project10_images/pr10.jpg);background-size:cover;background-position:50%;height:400px;display:flex;align-items:center;justify-content:center;color:#fff;text-align:center><div style=background-color:rgba(0,0,0,.4);padding:1rem;border-radius:4px><h1 class="f1 athelas mt3 mb1">PART 1. Colour Normalisation in Histopathology. Enhancing Medical Image Consistency: Colour Normalisation Techniques for Histopathology</h1><p class=f5>Explore how colour normalisation techniques can reduce staining variability in histopathology slides, improving the performance of machine learning models.</p></div></header><main class=pb7 role=main><article class="mw8 center ph3"><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray"><figure><img src=/images/project10_images/pr10.jpg></figure><p><strong>View Project on GitHub</strong>:</p><a href=https://github.com/drnsmith/ColourNorm-Histopathology-DeepLearning target=_blank><img src=/images/github.png alt=GitHub style=width:40px;height:40px;vertical-align:middle></a><h3 id=introduction>Introduction</h3><p>Histopathology, the microscopic study of tissue to detect diseases like cancer, heavily relies on stained images. However, variations in staining protocols, imaging devices, and lighting conditions can introduce inconsistencies, which pose a challenge for machine learning (ML) models.</p><p>Colour normalisation (CN) is a pre-processing step that standardises these images, ensuring consistency and enabling ML models to focus on disease-relevant features like cell shapes and abnormal structures. This blog explores:</p><ul><li>Why CN is essential in histopathology.</li><li>Key CN techniques, including <strong>Channel-Based Normalisation (CBN)</strong>, <strong>Color Deconvolution (CD)</strong>, and <strong>CLAHE</strong>.</li><li>Practical Python code snippets for implementation.</li></ul><h2 id=why-colour-normalisation-is-essential><strong>Why Colour Normalisation is Essential</strong></h2><p>Inconsistent staining can obscure the patterns ML models rely on, leading to reduced performance. CN addresses this by:</p><ul><li>Reducing variability caused by different staining protocols.</li><li>Standardising colour properties, enabling models to focus on relevant features.</li></ul><h3 id=experimental-objective><strong>Experimental Objective</strong></h3><p>To evaluate the impact of CN on histopathology workflows, I compared the following techniques:</p><ol><li><strong>Channel-Based Normalisation (CBN)</strong></li><li><strong>Color Deconvolution (CD)</strong></li><li><strong>CLAHE (Contrast Limited Adaptive Histogram Equalisation)</strong></li><li>Baseline (No CN applied)</li></ol><p>The results provide insights into which CN technique is most effective in improving ML model performance.</p><h2 id=key-colour-normalisation-techniques><strong>Key Colour Normalisation Techniques</strong></h2><h3 id=1-channel-based-normalisation-cbn><strong>1. Channel-Based Normalisation (CBN)</strong></h3><p>CBN adjusts each RGB channel of an image to match the mean and standard deviation of a reference image. This is effective for handling uniform staining variability.</p><p><strong>Code Snippet:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> cv2
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>channel_based_normalisation</span>(image, reference_image):
</span></span><span style=display:flex><span>    image <span style=color:#f92672>=</span> image<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>    reference <span style=color:#f92672>=</span> reference_image<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Split channels for both images</span>
</span></span><span style=display:flex><span>    img_channels <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>split(image)
</span></span><span style=display:flex><span>    ref_channels <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>split(reference)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Normalise each channel</span>
</span></span><span style=display:flex><span>    norm_channels <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> img_channel, ref_channel <span style=color:#f92672>in</span> zip(img_channels, ref_channels):
</span></span><span style=display:flex><span>        norm_channel <span style=color:#f92672>=</span> (img_channel <span style=color:#f92672>-</span> np<span style=color:#f92672>.</span>mean(img_channel)) <span style=color:#f92672>/</span> np<span style=color:#f92672>.</span>std(img_channel)
</span></span><span style=display:flex><span>        norm_channel <span style=color:#f92672>=</span> norm_channel <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>std(ref_channel) <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>mean(ref_channel)
</span></span><span style=display:flex><span>        norm_channels<span style=color:#f92672>.</span>append(norm_channel)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> cv2<span style=color:#f92672>.</span>merge(norm_channels)<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>uint8)
</span></span></code></pre></div><h3 id=2-color-deconvolution-cd><strong>2. Color Deconvolution (CD)</strong></h3><p>CD separates stains into distinct channels (e.g., Hematoxylin and Eosin), allowing targeted adjustments. This method is ideal for slides with multiple dyes.</p><p><strong>Code Snippet:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> skimage.color <span style=color:#f92672>import</span> rgb2hed
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>color_deconvolution</span>(image):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Perform color deconvolution to separate stains.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Returns the Hematoxylin (H), Eosin (E), and DAB (D) channels.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    hed <span style=color:#f92672>=</span> rgb2hed(image)
</span></span><span style=display:flex><span>    h, e, d <span style=color:#f92672>=</span> hed[:, :, <span style=color:#ae81ff>0</span>], hed[:, :, <span style=color:#ae81ff>1</span>], hed[:, :, <span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> h, e, d
</span></span></code></pre></div><p><strong>Visualisation Example:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Assuming `image` is loaded as a NumPy array</span>
</span></span><span style=display:flex><span>h, e, d <span style=color:#f92672>=</span> color_deconvolution(image)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>4</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Hematoxylin (H)&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>imshow(h, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Eosin (E)&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>imshow(e, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;DAB (D)&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>imshow(d, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h3 id=3-clahe-contrast-limited-adaptive-histogram-equalisation><strong>3. CLAHE (Contrast Limited Adaptive Histogram Equalisation)</strong></h3><p>CLAHE enhances image contrast, particularly in low-light regions, improving feature detection for ML models.</p><p><strong>Code Snippet:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>apply_clahe</span>(image, clip_limit<span style=color:#f92672>=</span><span style=color:#ae81ff>2.0</span>, tile_grid_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>8</span>)):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Apply CLAHE to improve image contrast.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    lab <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>cvtColor(image, cv2<span style=color:#f92672>.</span>COLOR_BGR2LAB)  <span style=color:#75715e># Convert to LAB color space</span>
</span></span><span style=display:flex><span>    l, a, b <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>split(lab)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Apply CLAHE to the L channel</span>
</span></span><span style=display:flex><span>    clahe <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>createCLAHE(clipLimit<span style=color:#f92672>=</span>clip_limit, tileGridSize<span style=color:#f92672>=</span>tile_grid_size)
</span></span><span style=display:flex><span>    l_clahe <span style=color:#f92672>=</span> clahe<span style=color:#f92672>.</span>apply(l)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Merge the channels back</span>
</span></span><span style=display:flex><span>    lab_clahe <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>merge((l_clahe, a, b))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> cv2<span style=color:#f92672>.</span>cvtColor(lab_clahe, cv2<span style=color:#f92672>.</span>COLOR_LAB2BGR)
</span></span></code></pre></div><p><strong>Results</strong>
The following experiments compared the performance of a DenseNet201 model trained with different CN techniques:</p><ul><li>Baseline (No CN): ~85% accuracy.</li><li>CBN: ~88% accuracy.</li><li>CD: ~90% accuracy.</li><li>CLAHE: ~89% accuracy.</li></ul><p><strong>Insights:</strong></p><p>CD outperformed other techniques, suggesting it is best suited for slides with distinct stains.
CLAHE was effective for low-contrast images but added computational overhead.</p><h3 id=conclusion>Conclusion</h3><p>Colour normalisation is a vital preprocessing step in medical imaging. By reducing staining variability, techniques like CBN, CD, and CLAHE ensure ML models focus on disease-relevant features. However, the choice of technique should be guided by the specific dataset and computational constraints.</p><p><em>Feel free to explore the project on GitHub and contribute if youâ€™re interested. Happy coding and stay healthy!</em></p></div></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=http://localhost:1313/>&copy; Natasha Smith Portfolio 2025</a><div><div class=ananke-socials></div></div></div></footer></body></html>