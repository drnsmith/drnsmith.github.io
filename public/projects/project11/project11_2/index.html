<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Part 2. Mastering Data Preparation and Augmentation: Building the Foundation for Better Image Classification Models. | Natasha Smith Portfolio</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="This blog delves into the critical role of data preparation and augmentation in image classification. From resizing and normalising images to handling class imbalance and applying augmentation, I’ll guide you through essential pre-processing techniques to ensure your deep learning models perform at their best.">

    <meta name="generator" content="Hugo 0.142.0">

    

    
<link rel="stylesheet" href="/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css" >



    <link rel="stylesheet" href="/css/custom.css">
    
  </head>

  <body class="ma0 avenir bg-near-white">
    
    <nav class="pa3 pa4-ns flex justify-end items-center">
    <ul class="list flex ma0 pa0">
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/">Home</a>
      </li>
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/about/">About</a>
      </li>
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/projects/">Projects</a>
      </li>
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/contact/">Contact</a>
      </li>
      
    </ul>
  </nav>
  
  

    
    
      
      <header class="page-header"
        style="
          background-image: url('/images/project11_images/pr11.jpg');
          background-size: cover;
          background-position: center;
          height: 400px;
          display: flex;
          align-items: center;
          justify-content: center;
          color: white;
          text-align: center;">
        <div style="background-color: rgba(0,0,0,0.4); padding: 1rem; border-radius: 4px;">
          <h1 class="f1 athelas mt3 mb1">
            Part 2. Mastering Data Preparation and Augmentation: Building the Foundation for Better Image Classification Models.
          </h1>
          
            <p class="f5">This blog delves into the critical role of data preparation and augmentation in image classification. From resizing and normalising images to handling class imbalance and applying augmentation, I’ll guide you through essential pre-processing techniques to ensure your deep learning models perform at their best.</p>
          
        </div>
      </header>
      
    

    
    <main class="pb7" role="main">
      
  <article class="mw8 center ph3">
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray"><figure><img src="/images/project11_images/pr11.jpg">
</figure>

<p><strong>View Project on GitHub</strong>:</p>
<a href="https://github.com/drnsmith/Custom-CNNs-Histopathology-Classification" target="_blank">
    <img src="/images/github.png" alt="GitHub" style="width:40px; height:40px; vertical-align: middle;">
  </a>
<h3 id="introduction">Introduction</h3>
<p>The journey to building a high-performing image classification model begins long before training. Data preparation and augmentation are often overlooked but vital steps in ensuring your model learns effectively and generalises well. These processes form the bridge between raw, unstructured data and the structured inputs a machine learning model can use.</p>
<p>In this blog, we will:</p>
<ul>
<li>Explore the essential techniques of data pre-processing, including resizing, normalization, and train-test splitting.</li>
<li>Learn how data augmentation enhances model generalisation.</li>
<li>Discuss strategies for addressing class imbalance to prevent biased models.</li>
<li>Show how these steps contribute to real-world applications like medical imaging and fraud detection.</li>
</ul>
<p>By the end, you’ll have a comprehensive understanding of why data preparation is the cornerstone of machine learning success.</p>
<h3 id="technical-explanation">Technical Explanation</h3>
<h4 id="why-data-preparation-matters">Why Data Preparation Matters</h4>
<p>Before diving into the specifics, let’s address the “why.” Data preparation ensures that:</p>
<ul>
<li><em>Models receive structured input</em>: Deep learning models expect data to follow a specific format, including consistent dimensions and value ranges.</li>
<li><em>Training is efficient</em>: Pre-processed data allows the model to converge faster by eliminating noise and redundancies.</li>
<li><em>Generalisation improves</em>: Techniques like augmentation create a diverse dataset, reducing the risk of overfitting.</li>
</ul>
<h3 id="key-techniques-in-data-preparation">Key Techniques in Data Preparation</h3>
<ul>
<li>
<ol>
<li>Loading and Pre-processing Images
<strong>Reading Images</strong>
Each image was loaded and resized to a standard dimension of 224x224 pixels to ensure consistency across the dataset. <code>OpenCV</code> and <code>TensorFlow</code> libraries were used for this task.</li>
</ol>
</li>
</ul>
<p>A function was created to load and pre-process the images:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function to load and pre-process images</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_images_from_folder</span>(folder, label):
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> file <span style="color:#f92672">in</span> os<span style="color:#f92672">.</span>listdir(folder):
</span></span><span style="display:flex;"><span>        img_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(folder, file)
</span></span><span style="display:flex;"><span>        img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(img_path)  <span style="color:#75715e"># Load image</span>
</span></span><span style="display:flex;"><span>        img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2RGB)  <span style="color:#75715e"># Convert to RGB</span>
</span></span><span style="display:flex;"><span>        img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(img, (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>))  <span style="color:#75715e"># Resize to 224x224</span>
</span></span><span style="display:flex;"><span>        data<span style="color:#f92672">.</span>append((img, label))  <span style="color:#75715e"># Append image and label</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> data
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load data for both classes</span>
</span></span><span style="display:flex;"><span>benign_data <span style="color:#f92672">=</span> load_images_from_folder(benign_dir, label<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>malignant_data <span style="color:#f92672">=</span> load_images_from_folder(malignant_dir, label<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span></code></pre></div><ul>
<li>
<ol start="2">
<li>Data Splitting
<strong>Train-Test Split</strong>
The dataset was split into training, validation, and test sets with an 80-10-10 ratio. The <code>train_test_split</code> function from sklearn was used.</li>
</ol>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Combine benign and malignant data</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> benign_data <span style="color:#f92672">+</span> malignant_data
</span></span><span style="display:flex;"><span>images, labels <span style="color:#f92672">=</span> zip(<span style="color:#f92672">*</span>data)
</span></span><span style="display:flex;"><span>images <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(images)
</span></span><span style="display:flex;"><span>labels <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(labels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Split data</span>
</span></span><span style="display:flex;"><span>X_train, X_temp, y_train, y_temp <span style="color:#f92672">=</span> train_test_split(images, labels, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>X_val, X_test, y_val, y_test <span style="color:#f92672">=</span> train_test_split(X_temp, y_temp, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Training set size: </span><span style="color:#e6db74">{</span>len(X_train)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Validation set size: </span><span style="color:#e6db74">{</span>len(X_val)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Test set size: </span><span style="color:#e6db74">{</span>len(X_test)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><ul>
<li>
<ol start="3">
<li>Resizing and Normalising Images
Images captured from real-world sources often come in varying sizes and resolutions. Resizing ensures uniformity, while normalization scales pixel values to [0, 1], preventing large gradients that could slow training.</li>
</ol>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preprocess_image</span>(image, target_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)):
</span></span><span style="display:flex;"><span>    resized_image <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(image, target_size)  <span style="color:#75715e"># Resize to target dimensions</span>
</span></span><span style="display:flex;"><span>    normalized_image <span style="color:#f92672">=</span> resized_image <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>       <span style="color:#75715e"># Normalize pixel values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> normalized_image
</span></span></code></pre></div><ul>
<li>
<ol start="4">
<li>Data Augmentation
<strong>Data augmentation</strong> artificially increases dataset size by creating variations of existing images. Common transformations include:</li>
</ol>
</li>
<li>
<p><em>Rotation</em>: Simulates different orientations.</p>
</li>
<li>
<p><em>Flipping</em>: Improves robustness to mirrored inputs.</p>
</li>
<li>
<p><em>Zooming</em>: Focuses on finer details.</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.preprocessing.image <span style="color:#f92672">import</span> ImageDataGenerator
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>datagen <span style="color:#f92672">=</span> ImageDataGenerator(
</span></span><span style="display:flex;"><span>    rotation_range<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>,
</span></span><span style="display:flex;"><span>    zoom_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
</span></span><span style="display:flex;"><span>    horizontal_flip<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>augmented_examples <span style="color:#f92672">=</span> [datagen<span style="color:#f92672">.</span>random_transform(train_images[<span style="color:#ae81ff">0</span>]) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">5</span>)]
</span></span></code></pre></div><figure><img src="/images/project11_images/examples.png">
</figure>

<ul>
<li>
<ol start="5">
<li>Handling Class Imbalance
In datasets with skewed class distributions, models tend to favor the majority class.
<figure><img src="/images/project11_images/split.png">
</figure>
</li>
</ol>
</li>
</ul>
<p><strong>Oversampling with Data Augmentation</strong>
I applied data augmentation to the minority class (benign images) to artificially increase its representation in the training data. This ensures the model is exposed to more diverse examples from the smaller class without altering the original dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.preprocessing.image <span style="color:#f92672">import</span> ImageDataGenerator
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Data augmentation for training data</span>
</span></span><span style="display:flex;"><span>datagen <span style="color:#f92672">=</span> ImageDataGenerator(
</span></span><span style="display:flex;"><span>    rotation_range<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>,
</span></span><span style="display:flex;"><span>    width_shift_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
</span></span><span style="display:flex;"><span>    height_shift_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
</span></span><span style="display:flex;"><span>    horizontal_flip<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    zoom_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply augmentation to training data</span>
</span></span><span style="display:flex;"><span>datagen<span style="color:#f92672">.</span>fit(X_train)
</span></span></code></pre></div><p><strong>Key Points:</strong></p>
<ul>
<li>Augmentation techniques like rotation, flips, zoom, and shifts were applied.</li>
<li>This approach creates variations of existing benign images to balance the dataset.</li>
</ul>
<p><strong>Weighted Loss Function</strong>
To account for the imbalance in class distribution, I applied class weights when compiling the model. This technique ensures the model assigns more importance to the minority class during training, reducing the likelihood of biased predictions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.utils.class_weight <span style="color:#f92672">import</span> compute_class_weight
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Compute class weights</span>
</span></span><span style="display:flex;"><span>class_weights <span style="color:#f92672">=</span> compute_class_weight(<span style="color:#e6db74">&#39;balanced&#39;</span>, classes<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>unique(y_train), y<span style="color:#f92672">=</span>y_train)
</span></span><span style="display:flex;"><span>class_weights <span style="color:#f92672">=</span> dict(enumerate(class_weights))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Class Weights: </span><span style="color:#e6db74">{</span>class_weights<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Pass class weights during model training</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fit(X_train, y_train, validation_data<span style="color:#f92672">=</span>(X_val, y_val), epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, class_weight<span style="color:#f92672">=</span>class_weights)
</span></span></code></pre></div><p><strong>Key Points:</strong></p>
<p>The <code>compute_class_weight</code> function calculates weights inversely proportional to class frequencies.
This ensures that the malignant class (majority) does not dominate the learning process.</p>
<p><strong>Stratified Sampling</strong>
I used stratified sampling when splitting the dataset into training, validation, and test sets. This maintains the original class distribution in each subset, ensuring balanced representation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Stratified split</span>
</span></span><span style="display:flex;"><span>X_train, X_temp, y_train, y_temp <span style="color:#f92672">=</span> train_test_split(images, labels, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, stratify<span style="color:#f92672">=</span>labels, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>X_val, X_test, y_val, y_test <span style="color:#f92672">=</span> train_test_split(X_temp, y_temp, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, stratify<span style="color:#f92672">=</span>y_temp, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span></code></pre></div><p><strong>Key Points:</strong></p>
<ul>
<li>The stratify parameter ensures each subset maintains the original class proportions.</li>
<li>This prevents under-representation of the minority class during training or testing.</li>
</ul>
<p><strong>Evaluation Metrics to Address Imbalance</strong>
I used metrics such as <strong>F1-score</strong>, <strong>Precision</strong>, <strong>Recall</strong>, and <strong>ROC-AUC</strong> instead of relying solely on accuracy. These metrics are more suitable for imbalanced datasets, as they account for the performance of each class independently.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report, roc_auc_score
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Evaluate model</span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>print(classification_report(y_test, y_pred <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate ROC-AUC</span>
</span></span><span style="display:flex;"><span>roc_auc <span style="color:#f92672">=</span> roc_auc_score(y_test, y_pred)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;ROC-AUC: </span><span style="color:#e6db74">{</span>roc_auc<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p><em><strong>Key Points:</strong></em></p>
<ul>
<li>The F1-score balances precision and recall, especially important for the minority class.</li>
<li>ROC-AUC provides a comprehensive measure of the model’s ability to distinguish between classes.</li>
</ul>
<h3 id="conclusion">Conclusion</h3>
<p>Data preparation is not just a preliminary step; it’s a foundation upon which robust models are built. By resizing, normalising, augmenting, and balancing datasets, you enable models to learn effectively and generalise well to unseen data.</p>
<h4 id="key-takeaways">Key Takeaways:</h4>
<ul>
<li>Uniformity in data input is critical for efficient training.</li>
<li>Data augmentation improves generalisation, reducing overfitting.</li>
<li>Addressing class imbalance prevents biased models.</li>
<li>Invest time in preparing your data—because in machine learning, quality input leads to quality output.</li>
</ul>
<p><em>Feel free to explore the project on GitHub and contribute if you’re interested. Happy coding and stay healthy!</em></p>
</div>
  </article>

    </main>

    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://drnsmith.github.io/" >
    &copy;  Natasha Smith Portfolio 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>


