<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>AI-Powered Recipe Classifier. | Natasha Smith Portfolio</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="I built an AI-powered tool for classifying recipe difficulty.">

    <meta name="generator" content="Hugo 0.142.0">

    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    <link rel="stylesheet" href="/css/custom.css">
    
  </head>

  <body class="ma0 avenir bg-near-white">
    
    <nav class="pa3 pa4-ns flex justify-end items-center">
    <ul class="list flex ma0 pa0">
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/">Home</a>
      </li>
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/about/">About</a>
      </li>
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/projects/">Projects</a>
      </li>
      
      <li class="ml3">
        <a class="link dim dark-gray f5" href="/contact/">Contact</a>
      </li>
      
    </ul>
  </nav>
  
  

    
    
      
      <header class="page-header"
        style="
          background-image: url('/images/project1_images/pr1.jpg');
          background-size: cover;
          background-position: center;
          height: 400px;
          display: flex;
          align-items: center;
          justify-content: center;
          color: white;
          text-align: center;">
        <div style="background-color: rgba(0,0,0,0.4); padding: 1rem; border-radius: 4px;">
          <h1 class="f1 athelas mt3 mb1">
            AI-Powered Recipe Classifier.
          </h1>
          
            <p class="f5">I built an AI-powered tool for classifying recipe difficulty.</p>
          
        </div>
      </header>
      
    

    
    <main class="pb7" role="main">
      
  <article class="mw8 center ph3">
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray"><figure><img src="/images/project1_images/pr1.jpg">
</figure>

<div style="display: flex; align-items: center; gap: 10px;">
    <a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank" style="text-decoration: none;">
        <img src="/images/github.png" alt="GitHub" style="width: 40px; height: 40px; vertical-align: middle;">
    </a>
    <a href="https://github.com/drnsmith/AI-Recipe-Classifier" target="_blank" style="font-weight: bold; color: black;">
        View Project on GitHub
    </a>
</div>
<h1 id="part-1">PART 1.</h1>
<h2 id="introduction"><strong>Introduction</strong></h2>
<p>Cooking varies in complexity. Some recipes are straightforward, while others demand precision, technique, and skill.</p>
<p>The challenge in this project was to develop a machine learning (ML) model that classifies recipes into four difficulty levels—<strong>Easy, Medium, Hard, and Very Hard</strong>—using <strong>Natural Language Processing (NLP)</strong> and <strong>Machine Learning (ML)</strong>.</p>
<p>In the first part, I focus on and walk you through <strong>data collection, cleaning, and pre-processing</strong>, which lay the foundation for training a robust ML model.</p>
<h2 id="why-pre-process-recipe-data"><strong>Why Pre-process Recipe Data?</strong></h2>
<p>Raw textual data in recipes is often noisy, containing <strong>special characters, punctuation, HTML tags, and non-standard formatting</strong>.</p>
<p>If left untreated, these irregularities can reduce the performance of NLP models. To ensure high-quality inputs for ML, I applied a <strong>multi-step text cleaning and transformation process</strong>, which:</p>
<ol>
<li><strong>Removes non-ASCII characters</strong> to eliminate unwanted symbols.</li>
<li><strong>Converts text to lowercase</strong> for uniformity.</li>
<li><strong>Removes non-contextual words</strong>, including newlines and HTML tags.</li>
<li><strong>Removes numbers</strong> as they don’t contribute to textual understanding.</li>
<li><strong>Removes punctuation</strong> to standardise input format.</li>
<li><strong>Applies lemmatisation and stemming</strong> to normalise words.</li>
<li><strong>Removes stopwords</strong> to retain only meaningful content.</li>
</ol>
<h3 id="1-loading-and-cleaning-data"><strong>1. Loading and Cleaning Data</strong></h3>
<p>First, I loaded the dataset into a <code>Pandas DataFrame</code> and defined various text-cleaning functions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> WordNetLemmatizer, PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> string
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load dataset into a DataFrame</span>
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;/path/to/recipes_data.csv&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialise NLTK resources</span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;punkt&#39;</span>)
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;stopwords&#39;</span>)
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;wordnet&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define cleaning utilities</span>
</span></span><span style="display:flex;"><span>lemmatizer <span style="color:#f92672">=</span> WordNetLemmatizer()
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span></code></pre></div><h4 id="explanation"><strong>Explanation:</strong></h4>
<ul>
<li>I used <strong>Pandas</strong> to load the recipe dataset.</li>
<li><strong>NLTK</strong> was used for tokenisation, stopword removal, and lemmatisation.</li>
<li>The stopwords list was initialised to filter out non-essential words (e.g., &ldquo;the&rdquo;, &ldquo;and&rdquo;, &ldquo;is&rdquo;).</li>
</ul>
<h3 id="2-text-cleaning-functions"><strong>2. Text Cleaning Functions</strong></h3>
<p>To ensure consistency, I created several text-cleaning functions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Function to remove non-ASCII characters</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_non_ascii</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;[^\x00-\x7F]&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function to convert text to lowercase</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">convert_to_lowercase</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>lower()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function to remove unnecessary symbols, HTML tags, and extra spaces</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_noncontext_words</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>)<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;&amp;nbsp&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\[.*?\]&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+|www\.\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function to remove numbers</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_numbers</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function to remove punctuation</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_punctuation</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>translate(str<span style="color:#f92672">.</span>maketrans(<span style="color:#e6db74">&#39;&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, string<span style="color:#f92672">.</span>punctuation))
</span></span></code></pre></div><h4 id="explanation-1"><strong>Explanation:</strong></h4>
<ul>
<li>These functions <strong>clean raw text</strong>, removed unwanted characters that could interfere with NLP processing.</li>
<li>URLs and unnecessary symbols were stripped out.</li>
<li>The text was <strong>lowercased</strong> to ensure uniform processing.</li>
</ul>
<h3 id="3-text-normalisation-with-nlp"><strong>3. Text Normalisation with NLP</strong></h3>
<p>Lemmatisation and stemming help <strong>normalise</strong> words by reducing them to their base forms.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Function to lemmatise text</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lemmatize_text</span>(text):
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join([lemmatizer<span style="color:#f92672">.</span>lemmatize(token) <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function to stem words</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stem_text</span>(text):
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join([stemmer<span style="color:#f92672">.</span>stem(token) <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens])
</span></span></code></pre></div><h4 id="explanation-2"><strong>Explanation:</strong></h4>
<ul>
<li><strong>Lemmatisation</strong> reduces words to their dictionary form (e.g., &ldquo;running&rdquo; → &ldquo;run&rdquo;).</li>
<li><strong>Stemming</strong> removes suffixes to simplify words (e.g., &ldquo;cooking&rdquo; → &ldquo;cook&rdquo;).</li>
</ul>
<h3 id="4-applying-pre-processing-to-recipe-data"><strong>4. Applying Pre-processing to Recipe Data</strong></h3>
<p>I applied all those cleaning steps to the dataset, ensuring that recipe data was properly structured before feeding it into the ML model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Comprehensive text pre-processing function</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preprocess_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> str(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_non_ascii(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> convert_to_lowercase(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_noncontext_words(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_numbers(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_punctuation(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> lemmatize_text(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> stem_text(text)
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> [lemmatizer<span style="color:#f92672">.</span>lemmatize(token) <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> token <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(set(tokens))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply pre-processing to relevant columns</span>
</span></span><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;preprocessed_ingredients&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;ingredients&#39;</span>]<span style="color:#f92672">.</span>apply(preprocess_text)
</span></span><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;preprocessed_directions&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;directions&#39;</span>]<span style="color:#f92672">.</span>apply(preprocess_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Combine columns for full recipe representation</span>
</span></span><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;preprocessed_full_recipe&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;preprocessed_ingredients&#39;</span>] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span> <span style="color:#f92672">+</span> df[<span style="color:#e6db74">&#39;preprocessed_directions&#39;</span>]
</span></span></code></pre></div><h4 id="explanation-3"><strong>Explanation:</strong></h4>
<ul>
<li>Each recipe’s <strong>ingredients and directions</strong> were pre-processed separately.</li>
<li>A <strong>combined column</strong> (<code>preprocessed_full_recipe</code>) was created to represent the entire recipe.</li>
</ul>
<h3 id="to-sum-this-part-up"><strong>To sum this part up,</strong></h3>
<p>Data pre-processing is a <strong>crucial first step</strong> in any NLP project. By cleaning and structuring text, I ensured the <strong>ML model receives high-quality inputs</strong> for training.</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>Cleaning text data removes noise and enhances NLP model performance.</li>
<li>Lemmatisation, stemming, and stopword removal improve text standardisation.</li>
<li>Pre-processed text is <strong>structured, compact, and informative</strong> for ML.</li>
</ul>
<h1 id="part-2">PART 2.</h1>
<h3 id="introduction-1">Introduction</h3>
<p>In ML, features are measurable characteristics or properties that help a model make predictions.</p>
<p>In recipe classification, features such as ingredient complexity, cooking techniques, and step count become powerful predictors of recipe difficulty.</p>
<p><strong>Feature engineering</strong> helps us take unstructured data, such as recipe instructions, and turn it into structured data that the model can understand.</p>
<p>For example, a recipe with advanced ingredients (like &ldquo;saffron&rdquo; or &ldquo;truffle oil&rdquo;) is likely to be more challenging than one with everyday items like &ldquo;salt&rdquo; or &ldquo;flour.&rdquo;</p>
<p>Similarly, recipes that involve techniques like &ldquo;blanching&rdquo; or &ldquo;flambé&rdquo; tend to require more skill than those involving basic steps like &ldquo;stirring.&rdquo;</p>
<p>In this part, I’ll take you behind the scenes into one of the most critical aspects of this project: <em>feature engineering</em>.</p>
<p>This is where raw recipe data is transformed into a format that AI can interpret. By selecting and creating features, my model gets the context it needs to classify recipes effectively.</p>
<h3 id="step-by-step-guide-to-key-features-in-recipe-classification">Step-by-Step Guide to Key Features in Recipe Classification</h3>
<p>To provide the model with a complete view of a recipe’s complexity, I engineered the following features:</p>
<h4 id="ingredients-complexity">Ingredients Complexity</h4>
<p>The ingredients of a recipe can offer a lot of information about its difficulty.</p>
<p>Because advanced or rare ingredients are generally associated with higher-difficulty recipes, to quantify ingredient complexity, I scored ingredients based on rarity and skill level.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Feature extraction for ingredient complexity</span>
</span></span><span style="display:flex;"><span>rare_ingredients <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;saffron&#34;</span>, <span style="color:#e6db74">&#34;truffle oil&#34;</span>, <span style="color:#e6db74">&#34;foie gras&#34;</span>]
</span></span><span style="display:flex;"><span>data[<span style="color:#e6db74">&#34;ingredient_complexity&#34;</span>] <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;ingredients&#34;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: sum(<span style="color:#ae81ff">1</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> rare_ingredients <span style="color:#66d9ef">if</span> i <span style="color:#f92672">in</span> x))
</span></span></code></pre></div><p>In this example, I created a list of rare ingredients and calculated the complexity score by counting how many rare ingredients appear in each recipe.</p>
<h4 id="technique-identification">Technique Identification</h4>
<p>Cooking techniques add another layer of difficulty.</p>
<p>A recipe that involves techniques like &ldquo;poaching&rdquo; or &ldquo;julienne&rdquo; is typically more complex than one that simply calls for &ldquo;stirring.&rdquo;</p>
<p>To identify and score these techniques, I used natural language processing (NLP). NLP kelped detecting specific terms associated with higher difficulty.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Feature extraction for technique complexity</span>
</span></span><span style="display:flex;"><span>advanced_techniques <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;julienne&#34;</span>, <span style="color:#e6db74">&#34;blanch&#34;</span>, <span style="color:#e6db74">&#34;poach&#34;</span>, <span style="color:#e6db74">&#34;flambé&#34;</span>]
</span></span><span style="display:flex;"><span>data[<span style="color:#e6db74">&#34;technique_complexity&#34;</span>] <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;steps&#34;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: sum(<span style="color:#ae81ff">1</span> <span style="color:#66d9ef">for</span> technique <span style="color:#f92672">in</span> advanced_techniques <span style="color:#66d9ef">if</span> technique <span style="color:#f92672">in</span> x))
</span></span></code></pre></div><p>By scanning each recipe for these advanced techniques, I assigned a score based on the presence of each technique.</p>
<h3 id="step-count-and-length-as-complexity-indicators">Step Count and Length as Complexity Indicators</h3>
<p>The number of steps and the length of instructions provide insight into a recipe’s complexity.</p>
<p>My assumption was: recipes with many steps or lengthy instructions are generally more challenging.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Extract step count and length as features</span>
</span></span><span style="display:flex;"><span>data[<span style="color:#e6db74">&#34;step_count&#34;</span>] <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;steps&#34;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: len(x<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;. &#34;</span>)))  <span style="color:#75715e"># Count sentences as steps</span>
</span></span><span style="display:flex;"><span>data[<span style="color:#e6db74">&#34;step_length&#34;</span>] <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;steps&#34;</span>]<span style="color:#f92672">.</span>apply(len)  <span style="color:#75715e"># Total character length of the steps</span>
</span></span></code></pre></div><p>In this example, I used <strong>sentence count</strong> as a proxy for step count, and character length as an indicator of instruction complexity.</p>
<p>Such features, when combined, create a profile of each recipe that our model can use to predict difficulty.</p>
<p>The more detailed the features, the better the model becomes at distinguishing between easy and difficult recipes.</p>
<h3 id="challenges-in-feature-engineering-for-textual-data">Challenges in Feature Engineering for Textual Data</h3>
<p>Working with textual data from recipes posed some unique challenges. Here’s how I tackled a few of them:</p>
<h4 id="handling-ambiguity-in-recipe-difficulty">Handling Ambiguity in Recipe Difficulty</h4>
<p>Recipe difficulty can be subjective. An experienced chef may find a recipe easy, while a novice finds it challenging.</p>
<p>To address this, I used broad categories (<code>Easy</code>, <code>Medium</code>, <code>Hard</code>, and <code>Very Hard</code>) to create a more generalised difficulty scale.</p>
<h4 id="data-imbalance">Data Imbalance</h4>
<p>The data was skewed toward certain difficulty levels, with many recipes labeled as <code>Easy</code>.</p>
<p>To address this imbalance, I used <code>SMOTE</code> (Synthetic Minority Over-sampling Technique): it synthesises new data points for under-represented classes, making it easier for the model to learn from all categories.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> imblearn.over_sampling <span style="color:#f92672">import</span> SMOTE
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply SMOTE to balance the classes in the training set</span>
</span></span><span style="display:flex;"><span>sm <span style="color:#f92672">=</span> SMOTE(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>X_balanced, y_balanced <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>fit_resample(X_train, y_train)
</span></span></code></pre></div><h4 id="dealing-with-informal-and-varying-language">Dealing with Informal and Varying Language</h4>
<p>Recipe instructions often contain informal language or vary in word choice. As discussed earlier, I applied lemmatisation and tokenisation to standardise terms, making it easier for the model to identify patterns.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> WordNetLemmatizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>lemmatizer <span style="color:#f92672">=</span> WordNetLemmatizer()
</span></span><span style="display:flex;"><span>data[<span style="color:#e6db74">&#34;steps&#34;</span>] <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;steps&#34;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join([lemmatizer<span style="color:#f92672">.</span>lemmatize(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> word_tokenize(x)]))
</span></span></code></pre></div><p>These pre-processing steps helped create consistency across the dataset, allowing the model to recognise terms despite variations in language.</p>
<h3 id="results-and-insights-on-feature-importance">Results and Insights on Feature Importance</h3>
<p>After training the model, I analysed feature importance to understand which features had the biggest impact on recipe difficulty predictions.</p>
<p>Ingredient complexity was a strong predictor of recipe difficulty. Recipes with rare ingredients tended to be more challenging.</p>
<p>Cooking techniques added nuance to the model, as advanced techniques were often associated with higher difficulty.</p>
<p>Step count and instruction length provided valuable context, as recipes with longer instructions were generally more difficult.</p>
<h4 id="visualisation-of-feature-importance">Visualisation of Feature Importance</h4>
<p>Below is a sample code snippet to visualise feature importance using <code>matplotlib</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Assuming model.feature_importances_ returns the importance of each feature</span>
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;Ingredient Complexity&#34;</span>, <span style="color:#e6db74">&#34;Technique Complexity&#34;</span>, <span style="color:#e6db74">&#34;Step Count&#34;</span>, <span style="color:#e6db74">&#34;Step Length&#34;</span>]
</span></span><span style="display:flex;"><span>importances <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>feature_importances_
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>barh(features, importances, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;skyblue&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Feature Importance&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Feature Importance in Recipe Difficulty Prediction&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>The bar chart it generates provides an at-a-glance view of which features contribute most to the classifier’s predictions.</p>
<h3 id="to-sum-up-this-part">To sum up this part,</h3>
<p>Feature engineering for my recipe difficulty classifier was as much about understanding cooking as it was about technical methods.</p>
<p>By quantifying culinary concepts like ingredient rarity and cooking techniques, I turned qualitative data into quantitative insights.</p>
<p>This not only enhances the model’s predictive power but also enriched the cooking experience by enabling personalised recipe suggestions.</p>
<h1 id="part-3">PART 3.</h1>
<h3 id="introduction-2">Introduction</h3>
<p>Next, I explored how feature engineering transforms raw recipe data into valuable insights for predicting recipe difficulty.</p>
<p>With features like ingredient complexity, technique identification, and step count, my dataset is now ready for the next stage: <strong>selecting, training, and evaluating</strong> a ML model that can classify recipes by difficulty level.</p>
<p>Model selection was a crucial step in building a successful classifier. In this part, I’ll walk you through the models I tested, the training process, and the metrics I used to evaluate performance.</p>
<h3 id="why-model-selection-matters">Why Model Selection Matters</h3>
<p>Choosing the right model is essential because each algorithm handles data differently.</p>
<p>A model that works well with structured numeric data might struggle with text-heavy datasets, while a model that excels with large datasets might not perform as well on smaller ones.</p>
<p>For this project, I tested several popular classification models:</p>
<ul>
<li>Naive Bayes (NB)</li>
<li>Support Vector Machines (SVM)</li>
<li>Random Forest (RF)</li>
</ul>
<p>Each model has unique strengths, and I wanted to determine which was best suited to handle the mixture of numerical and textual features in our recipe dataset.</p>
<h3 id="model-testing-and-selection-process">Model Testing and Selection Process</h3>
<h4 id="splitting-the-data">Splitting the Data</h4>
<p>To ensure our model performs well on unseen data, I split the dataset into training and test sets. The training set helps the model learn patterns, while the test set evaluates its generalisation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define features (X) and target (y)</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> data[[<span style="color:#e6db74">&#34;ingredient_complexity&#34;</span>, <span style="color:#e6db74">&#34;step_count&#34;</span>, <span style="color:#e6db74">&#34;technique_complexity&#34;</span>]]
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;difficulty&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Split the data into training and test sets</span>
</span></span><span style="display:flex;"><span>X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span></code></pre></div><h4 id="testing-different-models">Testing Different Models</h4>
<p>Each model has its own advantages, and I wanted to explore which one would be the best fit for the recipe classification task.</p>
<ul>
<li><strong>NB Classifier</strong></li>
</ul>
<p>The NB classifier is simple, fast, and works well for text-heavy datasets, but it assumes feature independence, which might not hold for my features.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.naive_bayes <span style="color:#f92672">import</span> MultinomialNB
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize and train the Naive Bayes model</span>
</span></span><span style="display:flex;"><span>nb_model <span style="color:#f92672">=</span> MultinomialNB()
</span></span><span style="display:flex;"><span>nb_model<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Predict and evaluate</span>
</span></span><span style="display:flex;"><span>nb_pred <span style="color:#f92672">=</span> nb_model<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Naive Bayes Accuracy:&#34;</span>, accuracy_score(y_test, nb_pred))
</span></span></code></pre></div><ul>
<li><strong>SVM</strong></li>
</ul>
<p>SVMs are powerful for classification tasks and perform well on smaller datasets, though they can be slower with larger data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.svm <span style="color:#f92672">import</span> SVC
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize and train the SVM model</span>
</span></span><span style="display:flex;"><span>svm_model <span style="color:#f92672">=</span> SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;linear&#34;</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>svm_model<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Predict and evaluate</span>
</span></span><span style="display:flex;"><span>svm_pred <span style="color:#f92672">=</span> svm_model<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;SVM Accuracy:&#34;</span>, accuracy_score(y_test, svm_pred))
</span></span></code></pre></div><ul>
<li><strong>RF Classifier</strong></li>
</ul>
<p>RF is an ensemble method that combines multiple decision trees, making it robust against overfitting and effective for mixed data types.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialise and train the Random Forest model</span>
</span></span><span style="display:flex;"><span>rf_model <span style="color:#f92672">=</span> RandomForestClassifier(n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>rf_model<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Predict and evaluate</span>
</span></span><span style="display:flex;"><span>rf_pred <span style="color:#f92672">=</span> rf_model<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Random Forest Accuracy:&#34;</span>, accuracy_score(y_test, rf_pred))
</span></span></code></pre></div><p>After testing these models, the <strong>RF classifier</strong> emerged as the most accurate for the dataset, with high accuracy and robustness to overfitting.</p>
<p>It was also flexible enough to handle the mix of numeric and text-derived features.</p>
<h3 id="model-training-and-hyperparameter-tuning">Model Training and Hyperparameter Tuning</h3>
<p>Once I selected RF, I fine-tuned its hyperparameters to optimise performance. Hyperparameters control aspects of the model, such as the number of trees in the forest or the maximum depth of each tree.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> GridSearchCV
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set up hyperparameter grid</span>
</span></span><span style="display:flex;"><span>param_grid <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;n_estimators&#34;</span>: [<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">150</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;max_depth&#34;</span>: [<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>],
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialise Grid Search for Random Forest</span>
</span></span><span style="display:flex;"><span>grid_search <span style="color:#f92672">=</span> GridSearchCV(estimator<span style="color:#f92672">=</span>RandomForestClassifier(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>), param_grid<span style="color:#f92672">=</span>param_grid, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;accuracy&#34;</span>)
</span></span><span style="display:flex;"><span>grid_search<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Best parameters</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Best Hyperparameters:&#34;</span>, grid_search<span style="color:#f92672">.</span>best_params_)
</span></span></code></pre></div><p>The grid search revealed the optimal combination of hyperparameters for my model, further boosting accuracy.</p>
<h3 id="evaluating-model-performance">Evaluating Model Performance</h3>
<p>With the final RF model trained, it was time to evaluate its performance. I used several metrics to assess its accuracy and predictive power:</p>
<ul>
<li><em>Accuracy</em>: The percentage of correct predictions.</li>
<li><em>Precision</em>: The proportion of true positives out of all positive predictions.</li>
<li><em>Recall:</em> The proportion of true positives out of all actual positives.</li>
<li><em>F1-Score</em>: The harmonic mean of precision and recall, balancing both metrics.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate a classification report</span>
</span></span><span style="display:flex;"><span>print(classification_report(y_test, rf_pred))
</span></span></code></pre></div><h4 id="understanding-the-metrics">Understanding the Metrics</h4>
<p><em>Accuracy</em> is useful for getting an overall sense of the model’s correctness.</p>
<p><em>Precision</em> is especially important when we want to minimise false positives, which might be useful in recommending recipes based on ease or complexity.</p>
<p><em>Recall</em> helps understand how well the model catches recipes within each difficulty class.</p>
<p><em>F1-Score</em> provides a balance, especially helpful in cases of data imbalance.</p>
<h3 id="key-takeaways">Key Takeaways</h3>
<p>Here’s what I learned from model selection and evaluation:</p>
<ul>
<li>RF outperformed Naive Bayes and SVM, handling the mix of numerical and textual data with ease.</li>
<li>Hyperparameter tuning further optimised my model, resulting in an accuracy of approximately 85%.</li>
<li>Evaluation metrics like precision and recall gave me a deeper understanding of the model’s performance across each difficulty level.</li>
</ul>
<h3 id="to-sum-up">To sum up,</h3>
<p>Selecting and training the right model was a crucial part of this recipe difficulty classifier.</p>
<p>Through careful testing and tuning, I developed a robust model that accurately classifies recipes by difficulty.</p>
<p>This classifier now has the potential to enhance user experiences on cooking platforms, helping chefs of all levels find recipes suited to their skill.</p>
<h1 id="part-4">PART 4.</h1>
<h3 id="introduction-3">Introduction</h3>
<p>As I progressed with training my AI-powered recipe classifier, I noticed a common issue creeping in: <em>overfitting</em>, which happens when a model performs well on the training data but struggles to generalise to new, unseen data.</p>
<p>In ML, this can result in poor accuracy on validation or test data. In this part, I’ll walk you through how I identified overfitting in my model and the steps I took to address it.</p>
<p>I’ll also explain the visual clues from training and validation loss/accuracy graphs that helped me recognise this issue.</p>
<h3 id="1-spotting-overfitting-through-training-metrics">1. Spotting Overfitting Through Training Metrics</h3>
<p>During the model training, I kept track of both training loss and validation loss as well as accuracy metrics for both datasets. Here&rsquo;s what I observed.</p>
<p><em>Loss</em>: Initially, both training and validation loss decreased, indicating the model was learning well.</p>
<p>However, after the first epoch, the training loss continued to drop, while validation loss began to increase. This divergence suggested the model was memorising training data rather than learning generalisable patterns.</p>
<p><em>Accuracy</em>: A similar trend appeared in the accuracy plot. While training accuracy increased steadily, validation accuracy plateaued and eventually decreased, another clear sign that overfitting was happening.</p>
<p>These visual cues were instrumental in understanding the model’s learning behaviour and prompted me to make adjustments to prevent further overfitting.</p>
<h3 id="2-techniques-i-used-to-address-overfitting">2. Techniques I Used to Address Overfitting</h3>
<p>To combat overfitting, I implemented several techniques commonly used in ML. Here’s what I tried and how each approach helped.</p>
<p>a. <em>Adding Dropout Layers</em>
Dropout is a regularisation technique that randomly “drops” a fraction of neurons in the neural network during training.</p>
<p>This prevents the model from relying too heavily on any particular neuron, which helps improve generalisation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> Dropout
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Adding Dropout layers after each Dense layer</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">128</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.5</span>))  <span style="color:#75715e"># Dropout rate of 50%</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">64</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.3</span>))  <span style="color:#75715e"># Dropout rate of 30%</span>
</span></span></code></pre></div><p>b. <em>Reducing Model Complexity</em>
Overly complex models with too many layers or neurons are prone to overfitting because they can “memorise” the training data.</p>
<p>Simplifying the model architecture can help reduce this effect. I reduced the number of neurons in each layer and removed unnecessary layers. This helped make the model less complex and more focused on capturing essential features rather than noise.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Simplified model architecture</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">64</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>, input_shape<span style="color:#f92672">=</span>(input_shape,)))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">32</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(num_classes, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span></code></pre></div><p>c. <em>Early Stopping</em>
Early stopping is a technique that halts training once the validation loss starts increasing, even if the training loss is still decreasing. This prevents the model from overfitting further.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.callbacks <span style="color:#f92672">import</span> EarlyStopping
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Setting up early stopping</span>
</span></span><span style="display:flex;"><span>early_stopping <span style="color:#f92672">=</span> EarlyStopping(monitor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;val_loss&#39;</span>, patience<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, restore_best_weights<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fitting the model with early stopping</span>
</span></span><span style="display:flex;"><span>history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(X_train, y_train, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, validation_data<span style="color:#f92672">=</span>(X_val, y_val), callbacks<span style="color:#f92672">=</span>[early_stopping])
</span></span></code></pre></div><p>d. <em>Data Augmentation</em>
Although more common in image processing, data augmentation can also benefit text-based models by generating variations of the original data.</p>
<p>In my case, I experimented with slight modifications in the dataset, like randomising ingredient order or rephrasing instructions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> textaugment <span style="color:#f92672">import</span> EDA
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>augmenter <span style="color:#f92672">=</span> EDA()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Example of augmenting a text sample</span>
</span></span><span style="display:flex;"><span>original_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Chop the onions finely.&#34;</span>
</span></span><span style="display:flex;"><span>augmented_text <span style="color:#f92672">=</span> augmenter<span style="color:#f92672">.</span>synonym_replacement(original_text)
</span></span><span style="display:flex;"><span>print(augmented_text)  <span style="color:#75715e"># Output could be a slight variation of the instruction</span>
</span></span></code></pre></div><p>e. <em>Regularisation Techniques</em>
Finally, <strong>L2 regularisation</strong> penalises large weights in the model, encouraging it to focus on smaller, more generalisable patterns.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.regularizers <span style="color:#f92672">import</span> l2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Adding L2 regularisation to dense layers</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">128</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>, kernel_regularizer<span style="color:#f92672">=</span>l2(<span style="color:#ae81ff">0.01</span>)))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">64</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>, kernel_regularizer<span style="color:#f92672">=</span>l2(<span style="color:#ae81ff">0.01</span>)))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(num_classes, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span></code></pre></div><h3 id="3-results-after-applying-these-techniques">3. Results After Applying These Techniques</h3>
<p>After implementing these techniques, I retrained the model and saw promising results:
<img src="/images/figure1.png" alt="Training and Validation Loss and Accuracy"></p>
<ul>
<li><em>Decreased Validation Loss</em>: Validation loss stabilised instead of diverging from training loss, as shown in the graph above.</li>
<li><em>Improved Generalisatio</em>n: Validation accuracy improved, meaning the model was now able to classify unseen recipes more accurately.</li>
</ul>
<p>The combination of these methods led to a more balanced performance across both training and validation sets, allowing the model to generalise better without compromising too much on training accuracy.</p>
<h3 id="to-sum-up-1">To sum up,</h3>
<p>Overfitting can be a challenging issue, especially when working with complex datasets like recipe classification.</p>
<p>However, with techniques like <strong>dropout, early stopping, data augmentation, and regularisation</strong>, I was able to create a model that performs well on both training and unseen data.</p>
<p>Understanding the balance between learning and generalisation is key, and monitoring training metrics is crucial to spotting overfitting early on.</p>
<h1 id="part-5">PART 5.</h1>
<h3 id="introduction-4">Introduction</h3>
<p>In building a recipe difficulty classifier, I wanted to make sure the model&rsquo;s predictions weren’t just accurate but also understandable.</p>
<p>For anyone working with ML, especially in fields where transparency is key, model interpretability is crucial. This is where <code>LIME</code> (Local Interpretable Model-Agnostic Explanations) comes in.</p>
<p>In this part, I’ll walk you through how I used <code>LIME</code> to make sense of my classifier’s decisions, ensuring that its predictions are grounded and explainable.</p>
<h3 id="why-model-interpretability-matters">Why Model Interpretability Matters</h3>
<p>ML models, particularly neural networks, are often referred to as &ldquo;black boxes.&rdquo; They can make accurate predictions, but understanding why they make those predictions can be difficult.</p>
<p>This lack of transparency can be problematic, especially when models are used in real-world applications where trust and accountability are essential.</p>
<p>For my recipe classifier, understanding the model’s reasoning process was essential. I wanted to know:</p>
<ul>
<li><em>Which ingredients or techniques contribute to the model classifying a recipe as &ldquo;Easy&rdquo; or &ldquo;Hard&rdquo;?</em></li>
<li><em>How does the model weigh different aspects of a recipe to arrive at a difficulty level?</em></li>
</ul>
<p>To answer these questions, I turned to LIME.</p>
<h3 id="what-is-lime">What is LIME?</h3>
<p><code>LIME</code> is a tool designed to explain the predictions of any ML model by creating an interpretable approximation of the model’s behaviour in the local region around a specific prediction.</p>
<p><code>LIME</code> doesn’t explain the entire model.</p>
<p>Instead, it explains individual predictions by perturbing input data and observing how the model’s output changes. By focusing on small regions around a prediction, <code>LIME</code> can help us understand what factors most influence that specific prediction.</p>
<p>In this project, <code>LIME</code> was ideal because it allowed me to interpret each individual prediction made by my recipe classifier, without needing to delve into the inner workings of the model itself.</p>
<h3 id="how-i-used-lime-in-the-recipe-classifier-project">How I Used LIME in the Recipe Classifier Project</h3>
<p>I chose a range of recipes across different difficulty levels (<code>Easy</code>, <code>Medium</code>, <code>Hard</code>, <code>Very Hard</code>) to see if the model’s predictions were consistent and explainable.
I used the <code>LIME</code> library in <code>Python</code> to generate explanations for individual predictions.</p>
<p><code>LIME</code> works by creating slightly modified versions of a data point (in this case, a recipe) and observing how these changes impact the model’s output.</p>
<p>For each recipe, it provided insights into the features (ingredients, techniques, etc.) that contributed to the model’s prediction. This allowed me to see which elements of a recipe were driving its difficulty classification.</p>
<p>My expectation was this.</p>
<p>For a recipe classified as &ldquo;Hard,&rdquo; <code>LIME</code> might highlight features like &ldquo;multiple steps&rdquo; or &ldquo;specialised techniques&rdquo; as important contributors to the prediction. For an &ldquo;Easy&rdquo; recipe, it might show that &ldquo;basic ingredients&rdquo; and &ldquo;few steps&rdquo; were key factors.</p>
<p>This way, <code>LIME</code> helped me verify that the model was focusing on the right aspects of the recipes when making its predictions.</p>
<p>To use <code>LIME</code>, I first needed to install the <code>LIME</code> package in <code>Python</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Importing the necessary packages</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> lime.lime_text <span style="color:#f92672">import</span> LimeTextExplainer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Creating an instance of LimeTextExplainer</span>
</span></span><span style="display:flex;"><span>explainer <span style="color:#f92672">=</span> LimeTextExplainer(class_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;Easy&#39;</span>, <span style="color:#e6db74">&#39;Medium&#39;</span>, <span style="color:#e6db74">&#39;Hard&#39;</span>, <span style="color:#e6db74">&#39;Very Hard&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Selecting a recipe to explain</span>
</span></span><span style="display:flex;"><span>recipe_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This recipe involves multiple steps including sautéing, baking, and requires specific equipment.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generating an explanation for the prediction</span>
</span></span><span style="display:flex;"><span>explanation <span style="color:#f92672">=</span> explainer<span style="color:#f92672">.</span>explain_instance(recipe_text, model<span style="color:#f92672">.</span>predict_proba, num_features<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Displaying the explanation</span>
</span></span><span style="display:flex;"><span>explanation<span style="color:#f92672">.</span>show_in_notebook()
</span></span></code></pre></div><ul>
<li><em>LimeTextExplainer</em>: Since my classifier takes recipe descriptions as input, I used LimeTextExplainer, which is designed for text data.</li>
<li><em>explain_instance</em>: This function generates an explanation for a single instance (in this case, a recipe) by examining how slight modifications to the input affect the prediction.</li>
</ul>
<p><img src="/images/figure2.png" alt="LIME Interpretations"></p>
<h3 id="observations-and-interpretations">Observations and Interpretations</h3>
<ul>
<li><strong>Prediction Confidence</strong>:</li>
</ul>
<p>The model assigned a high confidence score of 0.80 for class 0 (which represent a difficulty level &ldquo;Easy&rdquo;). Lower confidence scores were observed for the other classes, with the next highest probability at 0.20, indicating that the model is fairly certain about this classification.</p>
<ul>
<li><strong>Word Contribution</strong>:</li>
</ul>
<p><code>LIME</code> highlighted specific words within the recipe text that significantly influenced the model’s prediction. Words such as &ldquo;mixture,&rdquo; &ldquo;crumb,&rdquo; &ldquo;side,&rdquo; &ldquo;ingredient,&rdquo; and &ldquo;tomato&rdquo; were highlighted, suggesting they contributed notably to the classification decision.</p>
<ul>
<li><strong>Importance of Ingredients and Terminology</strong>:</li>
</ul>
<p>The highlighted words indicate that certain ingredients and cooking-related terminology play an essential role in the model’s decision-making process.</p>
<p>For instance, terms like &ldquo;mixture&rdquo; and &ldquo;crumb&rdquo; could be associated with easier preparation techniques, influencing the model towards a lower difficulty classification.</p>
<ul>
<li><strong>Possible Model Bias or Heuristics</strong>:</li>
</ul>
<p>The words selected by <code>LIME</code> might suggest that the model has learned certain heuristics, linking specific ingredients or preparation methods to particular difficulty levels.</p>
<p>If &ldquo;tomato&rdquo; and &ldquo;crumb&rdquo; consistently appear in easier recipes, the model may have learned to associate these words with simpler classifications.</p>
<p>This can sometimes reveal biases in the dataset, where certain words are overrepresented in specific difficulty categories.</p>
<ul>
<li><strong>Interpretability and Transparency</strong>:</li>
</ul>
<p>The use of LIME here provides transparency by breaking down the &ldquo;black box&rdquo; of the model, showing users which elements of the recipe text had the most influence on the predicted difficulty.</p>
<p>This insight allows to evaluate if the model’s reasoning aligns with human intuition and if adjustments are needed to improve fairness or reduce bias in the predictions.</p>
<p>By using <code>LIME</code>, I better understood which parts of the recipe text the model relies on, providing a clear path for refining the classifier or further tailoring it to match real-world perceptions of recipe difficulty.</p>
<h3 id="the-value-of-using-lime">The Value of Using LIME</h3>
<p><code>LIME</code> proved invaluable in my project for several reasons:</p>
<ul>
<li><strong>Trust</strong>: By understanding the model’s reasoning, I could trust its predictions more fully.</li>
<li><strong>Debugging</strong>: <code>LIME</code> helped me spot any potential issues where the model might be focusing on irrelevant details.</li>
<li><strong>User-Friendly Explanations</strong>: For anyone looking to use this model in a real-world application, <code>LIME</code> explanations provide a way to communicate model behaviour clearly and effectively.</li>
</ul>
<h3 id="limitations-and-next-steps">Limitations and Next Steps</h3>
<p>While <code>LIME</code> was incredibly helpful, it does have limitations:</p>
<ul>
<li><strong>Local Interpretations Only</strong>: <code>LIME</code> only explains individual predictions rather than providing a global view of the model.</li>
<li><strong>Approximation Errors</strong>: Since <code>LIME</code> creates a simplified model to approximate the main model’s behaviour, there can be minor errors in interpretation.</li>
</ul>
<p>In future iterations of this project, it would be beneficial to explore other interpretability methods, such as <code>SHAP (SHapley Additive exPlanations)</code>, which offers a more holistic view of feature importance across all predictions.</p>
<h3 id="to-sum-up-2">To sum up,</h3>
<p>Interpreting ML models is essential, especially in fields where transparency and accountability matter.</p>
<p>By using <code>LIME</code>, I was able to open up the &ldquo;black box&rdquo; of my recipe difficulty classifier, ensuring that its predictions were not only accurate but also explainable.</p>
<p>For anyone looking to build or use ML models responsibly, tools like LIME offer a powerful way to understand and trust the predictions that models make.</p>
<p>If you&rsquo;re building your own classifiers or predictive models, I highly recommend experimenting with <code>LIME</code>. It’s a valuable tool in making machine learning not just effective, but also transparent and reliable.</p>
<h1 id="part-6">PART 6.</h1>
<h3 id="introduction-5">Introduction</h3>
<p>Once a model that classifies recipes by difficulty level is built and trained, the next challenge is deploying it into a real-world environment.</p>
<p>Next, we’ll cover the process of moving our trained model from a development setting to a production environment.</p>
<p>Deployment enables the model to make predictions and serve users in real-time, opening up possibilities for applications like recipe recommendation engines, cooking assistant apps, or culinary content platforms.</p>
<h3 id="preparing-the-model-for-deployment">Preparing the Model for Deployment</h3>
<p>Before deploying, it&rsquo;s essential to package the model in a way that allows it to operate independently of the training environment. This preparation includes:</p>
<ul>
<li><em>Saving the Model</em>: Using a format like .h5 (for neural networks in TensorFlow/Keras) or .pkl (for scikit-learn models) allows us to save the model’s parameters and architecture.</li>
<li><em>Version Control</em>: Tracking different versions of the model helps in managing updates and improvements over time, especially when experimenting with new features or hyperparameters.</li>
</ul>
<p>I chose to save the model using the format compatible with my framework (<code>TensorFlow</code> for neural networks or a <code>joblib pickle</code> for RF) and documented the version with metadata, including the date, model type, and main hyperparameters.</p>
<h3 id="choosing-a-deployment-platform">Choosing a Deployment Platform</h3>
<p>Several platforms allow to serve ML models as an API, each with its own benefits:</p>
<ul>
<li><strong>Cloud Platforms</strong>: Services like AWS SageMaker, Google Cloud AI Platform, and Microsoft Azure provide scalable, managed environments for deploying ML models.</li>
<li><strong>Containerisation with Docker</strong>: Docker allows to create a lightweight, portable container that includes our model and its dependencies.</li>
</ul>
<p>This approach works well for deployments on any cloud provider or on-premises servers.</p>
<ul>
<li><strong>Serverless Options</strong>: Using serverless frameworks like AWS Lambda can reduce costs, especially if the model is only used intermittently.</li>
</ul>
<p>I deployed my model using Docker for easy scalability and flexibility, with the potential to transition to a cloud platform as usage grows.</p>
<h3 id="building-a-rest-api-for-the-model">Building a REST API for the Model</h3>
<p>To allow applications to interact with the model, I set up a <code>REST API</code>. This interface allows to send recipe data to the model and receive predictions on the recipe difficulty.</p>
<ul>
<li><em>Framework</em>: I used Flask, a lightweight <code>Python</code> web framework, to create the <code>API</code>. <code>Flask</code> enables to set up endpoints to receive requests, process data, and return predictions.</li>
<li><em>API Endpoints</em>: I set up the following key endpoints:
<ul>
<li><code>POST/predict</code>: Takes recipe data (ingredients, cooking steps) and returns the predicted difficulty level.</li>
<li><code>GET/health</code>: A simple endpoint to check if the model is running correctly.</li>
</ul>
</li>
</ul>
<p>See a sample of Flask code to handle incoming requests:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> flask <span style="color:#f92672">import</span> Flask, request, jsonify
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pickle
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>app <span style="color:#f92672">=</span> Flask(__name__)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#### Load the pre-trained model</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;recipe_model.pkl&#39;</span>, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> pickle<span style="color:#f92672">.</span>load(f)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@app.route</span>(<span style="color:#e6db74">&#39;/predict&#39;</span>, methods<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;POST&#39;</span>])
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict</span>():
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> request<span style="color:#f92672">.</span>json
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Process data for prediction (e.g., feature extraction)</span>
</span></span><span style="display:flex;"><span>    processed_data <span style="color:#f92672">=</span> preprocess(data)  <span style="color:#75715e"># Custom function</span>
</span></span><span style="display:flex;"><span>    prediction <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict([processed_data])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> jsonify({<span style="color:#e6db74">&#39;difficulty&#39;</span>: prediction[<span style="color:#ae81ff">0</span>]})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@app.route</span>(<span style="color:#e6db74">&#39;/health&#39;</span>, methods<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;GET&#39;</span>])
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">health</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> jsonify({<span style="color:#e6db74">&#39;status&#39;</span>: <span style="color:#e6db74">&#39;healthy&#39;</span>})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>    app<span style="color:#f92672">.</span>run()
</span></span></code></pre></div><h3 id="testing-and-validating-the-api">Testing and Validating the API</h3>
<p>Before releasing the <code>API</code>, I ensured it functions correctly under various conditions. Testing includes:</p>
<ul>
<li><em>Unit Testing</em>: Testing individual components, such as the pre-processing function and prediction generation.</li>
<li><em>Integration Testing</em>: Checking the entire flow, from data submission to receiving a prediction, to ensure everything works in unison.</li>
<li><em>Load Testing</em>: Simulating multiple requests to measure the system&rsquo;s capacity and response time, which is especially important for high-traffic applications.</li>
</ul>
<p>I used <code>Postman</code> for API testing, sending test requests to the <code>/predict</code> endpoint with sample data and confirming the model returned correct predictions.</p>
<h3 id="deploying-the-api-with-docker">Deploying the API with Docker</h3>
<p>To ensure our model API is portable and scalable, I containerised it with Docker.</p>
<p>Docker enables to package the application with all necessary dependencies, making it easier to deploy across different environments.</p>
<p>Here’s the <code>Dockerfile</code> that can be used to containerise the <code>Flask API</code>:</p>
<pre tabindex="0"><code>FROM python:3.8-slim

# Set the working directory
WORKDIR /app

# Copy requirements and install dependencies
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the application code
COPY . .

# Expose the port Flask will run on
EXPOSE 5000

# Run the Flask app
CMD [&#34;python&#34;, &#34;app.py&#34;]
</code></pre><p>Once the <code>Docker image</code> is built, it can be deployed on any server or cloud service that supports Docker.</p>
<h3 id="monitoring-and-maintaining-the-model">Monitoring and Maintaining the Model</h3>
<p>After deployment, it&rsquo;s crucial to monitor the model’s performance and update it as needed. Monitoring helps detecting issues early, such as model drift or performance degradation.</p>
<ul>
<li><strong>Logging</strong>: Log incoming requests, predictions, and any errors that occur. This data helps in diagnosing issues and optimising the model over time.</li>
<li><strong>Metrics</strong>: Track metrics like latency, error rates, and prediction accuracy over time.</li>
<li><strong>Scheduled Retraining</strong>: If model performance decreases, consider retraining with new data to adapt to changing recipe trends or ingredients.</li>
</ul>
<p>I set up basic logging and monitoring, and in the future, automated retraining  - to ensure the model remains effective - can be integrated.</p>
<h3 id="to-sum-up-3">To sum up,</h3>
<p>Deploying an AI model is an essential step in bringing ML solutions to end-users.</p>
<p>For my AI-powered recipe difficulty classifier, build a <code>REST API with Flask</code>, containerise it using <code>Docker</code>, and test it thoroughly to ensure reliability.</p>
<p>By monitoring and maintaining the model, we aim to provide a seamless experience for users seeking recipe insights.</p>
<p><em>Feel free to explore the project on GitHub and contribute if you’re interested. Happy coding and happy cooking!</em></p>
</div>
  </article>

    </main>

    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  Natasha Smith Portfolio 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>


